{"cells":[{"cell_type":"markdown","source":["# Prepare environment"],"metadata":{"id":"4j7knhXTDd9_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11095,"status":"ok","timestamp":1686751503328,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"},"user_tz":-540},"id":"Iq5EKmsmYzMY","outputId":"46ef58ae-313c-4f27-9e51-234451cb67b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"eNkqktCQujjO","executionInfo":{"status":"ok","timestamp":1686751509735,"user_tz":-540,"elapsed":6422,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"outputs":[],"source":["## Library import\n","import pandas as pd\n","import numpy as np\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objs as go\n","from plotly.subplots import make_subplots\n","import random\n","\n","from warnings import simplefilter\n","simplefilter('ignore')\n","\n","\n","## Model\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping()"]},{"cell_type":"code","source":["## Environment setup\n","COLAB = True # False: local environment\n","PROJECT_DIR = \"/content/drive/MyDrive/Project/CS565_IoT/\""],"metadata":{"id":"T8AnmrVhDGBW","executionInfo":{"status":"ok","timestamp":1686751509735,"user_tz":-540,"elapsed":17,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27933,"status":"ok","timestamp":1686751537652,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"},"user_tz":-540},"id":"fnj76a6yXKoA","outputId":"1f327f57-cdf3-46a3-973b-4aa957382a87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["if COLAB:\n","  ## Linkage Google Drive\n","  from google.colab import drive\n","  drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Set random seeds\n","\n","tf.random.set_seed(1)"],"metadata":{"id":"ZVHeUSAiDgo-","executionInfo":{"status":"ok","timestamp":1686751537653,"user_tz":-540,"elapsed":9,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsZ_gNF3_Cyg"},"source":["## Set Hyperparamenter for CNN Model"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"d4L6K00Y9PBf","executionInfo":{"status":"ok","timestamp":1686751537653,"user_tz":-540,"elapsed":8,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"outputs":[],"source":["## Data hyperparameter ##\n","\n","# Data information\n","original_path = PROJECT_DIR + \"Data/Third collection/\" # Data  path\n","total_csv_num = 12 # num of csv\n","each_emotion_csv_num = 6 # It must same count with negative.csv and positive.csv\n","minute = 3 # duration of recording (minute)\n","test_list = [5,6] # test data's name , e.g ) pos_5 is\n","\n","\n","# PPG signal Information\n","sampling_rate = 100 # sampling rate\n","chunk_num = minute*60*sampling_rate # num of ppg data per one csv\n","# Split data into chunk(train input)\n","window_sec = 10 # window size(second)\n","overlap_sec = 5 # overlap size(second)\n","total_chunk_per_csv = int((3*60-window_sec)/(window_sec-overlap_sec)+1) # The total number of chunks generated when extracting overlapping windows of a specified window size from each CSV.\n","\n","\n","## Model hyperparameter ##\n","cut_sample =  2*sampling_rate # using 2 seconds for prediction\n","class_num = 2\n","class_name = 'Valence'\n","activation_func = 'sigmoid'\n","loss_func = tf.keras.losses.BinaryCrossentropy(from_logits=False) # 'categorical_crossentropy'\n","epoch_num = 5\n","batch_num = 64\n","filter_num = 20\n","dense_num = 200\n","final_train_col = 'norm_outlier_removed_ppg' # final data for training"]},{"cell_type":"markdown","metadata":{"id":"OLp5QMJBbTsa"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"vNkZWqwH-5qI"},"source":["### Define Function"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ch-X0Guz-9GY","executionInfo":{"status":"ok","timestamp":1686751537654,"user_tz":-540,"elapsed":9,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"outputs":[],"source":["'''\n","Split data into input chunk\n","'''\n","\n","def extract_data_with_overlap(audio_df_col,window_sec,overlap_sec,sampling_rate=100):\n","    data_list = []\n","    window_size = window_sec*sampling_rate  # window size\n","    overlap = overlap_sec*sampling_rate  # overlap size\n","\n","    start = 0\n","    end = start + window_size\n","\n","    while end <= len(audio_df_col):\n","        temp_list = list(audio_df_col[start:end])\n","        data_list.append(temp_list)\n","        start += window_size - overlap\n","        end = start + window_size\n","\n","    return np.array(data_list)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2w93_7GZ_KFA","executionInfo":{"status":"ok","timestamp":1686751537654,"user_tz":-540,"elapsed":8,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"outputs":[],"source":["'''\n","Eliminate noise from the PPG signal, which is outside the range of human heart frequency.\n","'''\n","\n","###  Filter\n","'''\n","Use chebychef Filter\n","'''\n","order = 4  # filter's order\n","fs = 100  # sampling rate\n","lowcut = 0.8  # lowcut frequency\n","highcut = 3.5  # highcut frequency\n","rp = 1  # Maximum attenuation level of the passband(dB)\n","rs = 30  # Minimum attenuation level of the stopband (dB)\n","b, a = signal.cheby1(order, rp, [lowcut, highcut], fs=fs, btype='band')\n","\n","\n","### Outlier removal\n","'''\n","If value of |z-score| > 3.5 then, remove\n","'''\n","\n","def outliers_modified_z(dataframe, threshold=3.5):\n","    data = dataframe.copy()\n","    median = np.median(data)\n","    median_absolute_deviation = np.median(np.abs(data - median))\n","    modified_z_scores = 0.6745 * (data - median) / median_absolute_deviation\n","    outliers = np.abs(modified_z_scores) > threshold\n","    data[outliers] = median\n","    return data\n","\n","def test_outliers_modified_z(test_dataframe,train_dataframe_data ,threshold=3.5):\n","    data = test_dataframe.copy()\n","    median = np.median(train_dataframe_data)\n","    median_absolute_deviation = np.median(np.abs(data - median))\n","    modified_z_scores = 0.6745 * (data - median) / median_absolute_deviation\n","    outliers = np.abs(modified_z_scores) > threshold\n","    data[outliers] = median\n","    return data\n","\n","\n","### Normalization\n","'''\n","Apply Standard Normalization\n","'''\n","def standard_scaler(data):\n","    mean = np.mean(data) #\n","    std = np.std(data) #\n","    scaled_data = (data - mean) / std\n","    return scaled_data\n","\n","def test_standard_scaler(data,audio_df_data):\n","    mean = np.mean(data) #\n","    std = np.std(data) #\n","    scaled_data = (data - mean) / std\n","    return scaled_data\n","\n","\n","### Final code\n","'''\n","apply Preprocessing to PPG\n","'''\n","def Preprocessing(dataframe):\n","  df = dataframe.copy()\n","  df['filtered_ppg'] = signal.filtfilt(b, a, df['ppg'])\n","  df['outlier_removed_ppg'] = outliers_modified_z(df['ppg'])\n","  df['filtered_and_outlier_removed_ppg'] = outliers_modified_z(df['filtered_ppg'])\n","  for col in df.columns:\n","    name = \"norm_{}\".format(col)\n","    df[name] = standard_scaler(df[col])\n","\n","  return df\n","\n","def Preprocessing_test(test_dataframe,train_dataframe):\n","  df = test_dataframe.copy()\n","  df['filtered_ppg'] = signal.filtfilt(b, a, df['ppg'])\n","  df['outlier_removed_ppg'] = test_outliers_modified_z(df['ppg'],train_dataframe['ppg'])\n","  df['filtered_and_outlier_removed_ppg'] = outliers_modified_z(df['filtered_ppg'])\n","  for col in df.columns:\n","    name = \"norm_{}\".format(col)\n","    df[name] =  test_standard_scaler(df[col],train_dataframe[col])\n","\n","  return df"]},{"cell_type":"markdown","metadata":{"id":"OjkW3BjX--Dg"},"source":["### Make train data"]},{"cell_type":"code","source":["# Split Data into Train and Test data\n","train_list = list(range(1,each_emotion_csv_num+1,1))\n","for num in test_list:\n","  train_list.remove(num)"],"metadata":{"id":"KoP6EnVCb9_b","executionInfo":{"status":"ok","timestamp":1686751537654,"user_tz":-540,"elapsed":7,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["##### Train #####\n","\n","audio_df = pd.DataFrame(columns=['ppg'])\n","\n","for i in train_list:\n","  col = \"audio_pos_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1] #\n","  audio_df = pd.concat([audio_df,temp],axis=0)\n","\n","for i in train_list:\n","  col = \"audio_neg_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1]\n","  audio_df = pd.concat([audio_df,temp],axis=0)\n","\n","audio_df = audio_df[[0]]\n","audio_df.columns = ['ppg']\n","\n","## Preprocessing\n","audio_df = Preprocessing(audio_df)\n","\n","## Split Data into chunk\n","audio_total = pd.DataFrame(columns=audio_df.columns)\n","for col in audio_df.columns:\n","  idx = 0\n","  for i in range(0,chunk_num*(total_csv_num),chunk_num):\n","    audio_temp = extract_data_with_overlap(audio_df.iloc[i:(i+chunk_num),:][col].values,window_sec,overlap_sec,sampling_rate) ## 각 dataset마다 10초 간격의 데이터를 5초 ovelap하게 하나의 리스트로 뽑음\n","\n","    for j in range(audio_temp.shape[0]):\n","      audio_total.loc[j + idx,col] = audio_temp[j]\n","    idx += audio_temp.shape[0]\n","\n","## Attach label informatoin\n","audio_total['Valence'] =[0]*total_chunk_per_csv*len(train_list)+ [1]*total_chunk_per_csv*len(train_list)\n","\n","## Split train and test set and random suffle\n","shuffled_train = audio_total.sample(frac=1, random_state=42).reset_index(drop=True)"],"metadata":{"id":"fH8P9MZEYRBT","executionInfo":{"status":"ok","timestamp":1686751548942,"user_tz":-540,"elapsed":11294,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7MgGNitxvFl"},"source":["## Train Model"]},{"cell_type":"code","source":["## Evaluation Metric\n","from sklearn.metrics import roc_auc_score\n","def roc_auc(y_true, y_pred):\n","    auc = tf.py_function(roc_auc_score, (y_true, y_pred), tf.float32)\n","    return auc"],"metadata":{"id":"4msq6mYIOGWq","executionInfo":{"status":"ok","timestamp":1686751548943,"user_tz":-540,"elapsed":7,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZHL45YkTzNa"},"source":["### Model Structure\n","    - Input - 200 sample\n","    - Conv1\n","        - Conv1D, 3*1 convolutional filter, 20 feature maps, stride 1 , padding of size one\n","        - BN\n","        - Max-pooling layer with a 2*1 filter\n","    - Dense1\n","        - 200 nodes"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53058,"status":"ok","timestamp":1686751601996,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"},"user_tz":-540},"id":"bZMGp18XjbDn","outputId":"72245003-59c6-4b4c-90c1-3e21019984c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","5/5 [==============================] - 24s 34ms/step - loss: 1.1089 - accuracy: 0.5179 - auc: 0.4921\n","Epoch 2/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.7083 - accuracy: 0.6250 - auc: 0.6839\n","Epoch 3/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7643 - auc: 0.7863\n","Epoch 4/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.8357 - auc: 0.8710\n","Epoch 5/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8750 - auc: 0.9242\n","Epoch 1/5\n","5/5 [==============================] - 2s 8ms/step - loss: 1.3548 - accuracy: 0.4571 - auc: 0.4592\n","Epoch 2/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.8975 - accuracy: 0.5536 - auc: 0.5543\n","Epoch 3/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.8662 - accuracy: 0.6071 - auc: 0.5989\n","Epoch 4/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.7713 - accuracy: 0.6036 - auc: 0.6281\n","Epoch 5/5\n","5/5 [==============================] - 0s 9ms/step - loss: 0.7472 - accuracy: 0.6429 - auc: 0.6377\n","Epoch 1/5\n","5/5 [==============================] - 3s 9ms/step - loss: 1.1294 - accuracy: 0.4821 - auc: 0.4907\n","Epoch 2/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.5921 - accuracy: 0.7071 - auc: 0.7801\n","Epoch 3/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8893 - auc: 0.9370\n","Epoch 4/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.3104 - accuracy: 0.9357 - auc: 0.9770\n","Epoch 5/5\n","5/5 [==============================] - 0s 9ms/step - loss: 0.2371 - accuracy: 0.9536 - auc: 0.9895\n","Epoch 1/5\n","5/5 [==============================] - 2s 7ms/step - loss: 1.0621 - accuracy: 0.4786 - auc: 0.4900\n","Epoch 2/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.7036 - auc: 0.7448\n","Epoch 3/5\n","5/5 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7643 - auc: 0.8086\n","Epoch 4/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8500 - auc: 0.8939\n","Epoch 5/5\n","5/5 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8536 - auc: 0.9178\n","Epoch 1/5\n","5/5 [==============================] - 2s 7ms/step - loss: 1.1777 - accuracy: 0.4357 - auc: 0.4769\n","Epoch 2/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.7036 - auc: 0.7130\n","Epoch 3/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7607 - auc: 0.8200\n","Epoch 4/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8107 - auc: 0.8791\n","Epoch 5/5\n","5/5 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8679 - auc: 0.9386\n","Epoch 1/5\n","5/5 [==============================] - 2s 7ms/step - loss: 1.2867 - accuracy: 0.4786 - auc: 0.5073\n","Epoch 2/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.9324 - accuracy: 0.5857 - auc: 0.5527\n","Epoch 3/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.8441 - accuracy: 0.6214 - auc: 0.6036\n","Epoch 4/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.8164 - accuracy: 0.5714 - auc: 0.6223\n","Epoch 5/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.7465 - accuracy: 0.6143 - auc: 0.6306\n","Epoch 1/5\n","5/5 [==============================] - 2s 7ms/step - loss: 1.1655 - accuracy: 0.5143 - auc: 0.5249\n","Epoch 2/5\n","5/5 [==============================] - 0s 6ms/step - loss: 0.6413 - accuracy: 0.7893 - auc: 0.7960\n","Epoch 3/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.4519 - accuracy: 0.8821 - auc: 0.9291\n","Epoch 4/5\n","5/5 [==============================] - 0s 9ms/step - loss: 0.2953 - accuracy: 0.9393 - auc: 0.9677\n","Epoch 5/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.2298 - accuracy: 0.9750 - auc: 0.9941\n","Epoch 1/5\n","5/5 [==============================] - 3s 10ms/step - loss: 1.0286 - accuracy: 0.4786 - auc: 0.4960\n","Epoch 2/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.5910 - accuracy: 0.7643 - auc: 0.7668\n","Epoch 3/5\n","5/5 [==============================] - 0s 10ms/step - loss: 0.4663 - accuracy: 0.8000 - auc: 0.8637\n","Epoch 4/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.3570 - accuracy: 0.8893 - auc: 0.9313\n","Epoch 5/5\n","5/5 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.9036 - auc: 0.9546\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping()\n","\n","deep_model = {}\n","for col in audio_total.columns[:-1]:\n","\n","    ## train set ##\n","    X_train = np.stack(shuffled_train[col].values,axis=0)\n","    y_train = to_categorical(shuffled_train[class_name])\n","    X_train = X_train[:,:cut_sample]\n","\n","    model = keras.models.Sequential([\n","      keras.layers.Conv1D(\n","          input_shape=(cut_sample,1), # 4 rows and 1 columns\n","          kernel_size=3, # the size of the window or the receptive field\n","          strides=1, # Sliding size\n","          filters=filter_num, # The number of filters\n","          padding=\"valid\",\n","          name = 'Conv1_CNN'\n","      ),\n","      keras.layers.BatchNormalization(name='Conv1_BN'),\n","      keras.layers.MaxPool1D(\n","          pool_size=2,\n","          strides=2,\n","          name = \"Conv1_MaxPool\"\n","      ),\n","      keras.layers.Flatten(),\n","      keras.layers.Dense(dense_num, activation='relu'),\n","      keras.layers.Dense(class_num, activation=activation_func)\n","    ])\n","\n","    model.compile(loss = loss_func, optimizer = 'adam', metrics = ['accuracy',\"AUC\"])\n","    model.fit(X_train, y_train, batch_size = batch_num, epochs = epoch_num, verbose = 1)\n","    deep_model[col] = [model]\n","\n"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ln4I5AtOJTe","executionInfo":{"status":"ok","timestamp":1686751601997,"user_tz":-540,"elapsed":32,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}},"outputId":"c0336625-51e6-4a09-f1bd-92992d12b5e6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Conv1_CNN (Conv1D)          (None, 198, 20)           80        \n","                                                                 \n"," Conv1_BN (BatchNormalizatio  (None, 198, 20)          80        \n"," n)                                                              \n","                                                                 \n"," Conv1_MaxPool (MaxPooling1D  (None, 99, 20)           0         \n"," )                                                               \n","                                                                 \n"," flatten_7 (Flatten)         (None, 1980)              0         \n","                                                                 \n"," dense_14 (Dense)            (None, 200)               396200    \n","                                                                 \n"," dense_15 (Dense)            (None, 2)                 402       \n","                                                                 \n","=================================================================\n","Total params: 396,762\n","Trainable params: 396,722\n","Non-trainable params: 40\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Test Model"],"metadata":{"id":"ymy1Jw4jY09X"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","for i in test_list:\n","  print(i,\"'s result\")\n","  audio_test = pd.DataFrame(columns=['ppg'])\n","\n","  col = \"audio_pos_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1] #\n","  audio_test = pd.concat([audio_test,temp],axis=0)\n","\n","  col = \"audio_neg_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1]\n","  audio_test = pd.concat([audio_test,temp],axis=0)\n","\n","  audio_test = audio_test[[0]]\n","  audio_test.columns = ['ppg']\n","\n","  audio_test = Preprocessing_test(audio_test,audio_df)\n","\n","  # label\n","  repeat_num = int(minute*60/window_sec)\n","  label_list = [0]*repeat_num + [1]*repeat_num\n","  label = pd.DataFrame(label_list,columns=['Valence_binary'])\n","\n","  for col in deep_model.keys():\n","    X_test_real = audio_test[col].values.reshape(-1,1000)\n","    y_test_real = label['Valence_binary']\n","    y_test_real_onehot = to_categorical(y_test_real)\n","    # print(X_test_real.shape,y_test_real.shape,y_test_real_onehot.shape)\n","\n","    model = deep_model[col][0]\n","    X_test = X_test_real[:,:cut_sample]\n","    y_test = y_test_real_onehot\n","\n","    y_predict = model.predict(X_test)\n","\n","    print('##############',col,'################')\n","    print(\"acc : \", accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict, axis=1)))\n","    print(\"auc : \",roc_auc(y_test,y_predict))\n","    print(\"origin label : \" ,np.argmax(y_test, axis=1))\n","    print(\"predict label : \",np.argmax(y_predict, axis=1))\n","    print()\n","\n","  print()\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm1kB3JumVBP","executionInfo":{"status":"ok","timestamp":1686751605834,"user_tz":-540,"elapsed":3858,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}},"outputId":"414c689f-5be0-4e6b-b3df-6bf60cada3f0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["5 's result\n","2/2 [==============================] - 0s 25ms/step\n","############## ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.5, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 4ms/step\n","############## filtered_ppg ################\n","acc :  0.3611111111111111\n","auc :  tf.Tensor(0.33487654, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0]\n","\n","2/2 [==============================] - 0s 4ms/step\n","############## outlier_removed_ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.5, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## filtered_and_outlier_removed_ppg ################\n","acc :  0.3611111111111111\n","auc :  tf.Tensor(0.25308642, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0]\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6bbd0dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step\n","############## norm_ppg ################\n","acc :  0.3611111111111111\n","auc :  tf.Tensor(0.31635803, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1]\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6bbd0e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step\n","############## norm_filtered_ppg ################\n","acc :  0.3333333333333333\n","auc :  tf.Tensor(0.35339507, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## norm_outlier_removed_ppg ################\n","acc :  0.3888888888888889\n","auc :  tf.Tensor(0.3904321, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## norm_filtered_and_outlier_removed_ppg ################\n","acc :  0.3055555555555556\n","auc :  tf.Tensor(0.23765433, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0]\n","\n","\n","\n","6 's result\n","2/2 [==============================] - 0s 6ms/step\n","############## ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.5, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## filtered_ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.49074075, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## outlier_removed_ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.5, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## filtered_and_outlier_removed_ppg ################\n","acc :  0.5555555555555556\n","auc :  tf.Tensor(0.587963, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n","\n","2/2 [==============================] - 0s 4ms/step\n","############## norm_ppg ################\n","acc :  0.4444444444444444\n","auc :  tf.Tensor(0.4675926, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1]\n","\n","2/2 [==============================] - 0s 4ms/step\n","############## norm_filtered_ppg ################\n","acc :  0.5\n","auc :  tf.Tensor(0.4351852, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## norm_outlier_removed_ppg ################\n","acc :  0.6111111111111112\n","auc :  tf.Tensor(0.6944444, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1]\n","\n","2/2 [==============================] - 0s 5ms/step\n","############## norm_filtered_and_outlier_removed_ppg ################\n","acc :  0.6666666666666666\n","auc :  tf.Tensor(0.6435185, shape=(), dtype=float32)\n","origin label :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","predict label :  [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1]\n","\n","\n","\n"]}]},{"cell_type":"code","source":["## Results ##\n","\n","'''\n","\n","all is not Good..\n","\n","But, we finalize the system\n","\n","'''"],"metadata":{"id":"upDKHam5h5-p","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1686751605835,"user_tz":-540,"elapsed":25,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}},"outputId":"8abdd68d-7254-46eb-ca1e-930796a37b6f"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nall is not Good..\\n\\nBut, we finalize the system\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# Make Train model for Arduino"],"metadata":{"id":"ZqplgKZffZVG"}},{"cell_type":"markdown","source":["## Update hyperparamaters for Arduino"],"metadata":{"id":"mnCrVTWxFmi5"}},{"cell_type":"code","source":["filter_num = 5 # before: 20\n","dense_num = 50 # before: 200"],"metadata":{"id":"MCDjNRKeFmRr","executionInfo":{"status":"ok","timestamp":1686751605835,"user_tz":-540,"elapsed":7,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Prepare dataset and train a model"],"metadata":{"id":"JWkmhnBtFxVO"}},{"cell_type":"code","source":["# Split Data into Train and Test data\n","\n","train_list = list(range(1,each_emotion_csv_num+1,1))\n","\n","##### Train #####\n","\n","audio_df = pd.DataFrame(columns=['ppg'])\n","\n","for i in train_list:\n","  col = \"audio_pos_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1] #\n","  audio_df = pd.concat([audio_df,temp],axis=0)\n","\n","for i in train_list:\n","  col = \"audio_neg_{}\".format(i)\n","  temp = pd.read_csv(original_path + col + '.csv')\n","  temp = temp.iloc[:3*60*100,1]\n","  audio_df = pd.concat([audio_df,temp],axis=0)\n","\n","audio_df = audio_df[[0]]\n","audio_df.columns = ['ppg']\n","\n","## Preprocessing\n","audio_df = Preprocessing(audio_df)\n","\n","## Split Data into chunk\n","audio_total = pd.DataFrame(columns=audio_df.columns)\n","for col in audio_df.columns:\n","  idx = 0\n","  for i in range(0,chunk_num*(total_csv_num),chunk_num):\n","    audio_temp = extract_data_with_overlap(audio_df.iloc[i:(i+chunk_num),:][col].values,window_sec,overlap_sec,sampling_rate) ## 각 dataset마다 10초 간격의 데이터를 5초 ovelap하게 하나의 리스트로 뽑음\n","\n","    for j in range(audio_temp.shape[0]):\n","      audio_total.loc[j + idx,col] = audio_temp[j]\n","    idx += audio_temp.shape[0]\n","\n","## Attach label informatoin\n","audio_total['Valence'] =[0]*total_chunk_per_csv*len(train_list)+ [1]*total_chunk_per_csv*len(train_list)\n","\n","## Split train and test set and random suffle\n","shuffled_train = audio_total.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping()\n","\n","\n","## train set ##\n","\n","X_train = np.stack(shuffled_train[final_train_col].values,axis=0)\n","y_train = to_categorical(shuffled_train[class_name])\n","X_train = X_train[:,:cut_sample]\n","\n","model = keras.models.Sequential([\n","  keras.layers.Conv1D(\n","          input_shape=(cut_sample,1), # 4 rows and 1 columns\n","          kernel_size=3, # the size of the window or the receptive field\n","          strides=1, # Sliding size\n","          filters=filter_num, # The number of filters\n","          padding=\"valid\",\n","          name = 'Conv1_CNN'\n","      ),\n","      keras.layers.BatchNormalization(name='Conv1_BN'),\n","      keras.layers.MaxPool1D(\n","          pool_size=2,\n","          strides=2,\n","          name = \"Conv1_MaxPool\"\n","      ),\n","      keras.layers.Flatten(),\n","      keras.layers.Dense(dense_num, activation='relu'),\n","      keras.layers.Dense(class_num, activation=activation_func)\n","    ])\n","\n","model.compile(loss = loss_func, optimizer = 'adam', metrics = ['accuracy',\"AUC\"])\n","model.fit(X_train, y_train, batch_size = batch_num, epochs = epoch_num, verbose = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDy1A5LqfYrs","executionInfo":{"status":"ok","timestamp":1686751611454,"user_tz":-540,"elapsed":5625,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}},"outputId":"0bf1a322-c8aa-4932-8c52-1121e87c4dc7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","7/7 [==============================] - 2s 15ms/step - loss: 0.7923 - accuracy: 0.5286 - auc: 0.5323\n","Epoch 2/5\n","7/7 [==============================] - 0s 6ms/step - loss: 0.6581 - accuracy: 0.6190 - auc: 0.6638\n","Epoch 3/5\n","7/7 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.6929 - auc: 0.7529\n","Epoch 4/5\n","7/7 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7452 - auc: 0.8110\n","Epoch 5/5\n","7/7 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7690 - auc: 0.8416\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb6bbeca950>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Save the model"],"metadata":{"id":"o69TZcCtFFfp"}},{"cell_type":"code","source":["import os\n","\n","MODELS_DIR = PROJECT_DIR + \"Models/\"\n","MODEL_TF = MODELS_DIR + \"model.keras\"\n","\n","os.makedirs(MODELS_DIR, exist_ok=True)\n","model.save(MODEL_TF)"],"metadata":{"id":"e-Prm3JoEuHI","executionInfo":{"status":"ok","timestamp":1686751612458,"user_tz":-540,"elapsed":1025,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["mean = np.mean(audio_df['ppg'])\n","std = np.std(audio_df['ppg'])\n","median = np.median(audio_df['ppg'])\n","median_absolute_deviation = np.median(np.abs(audio_df['ppg'] - median))\n","\n","print(\"median : \", median) # for outlier removal\n","print(\"MAD : \", median_absolute_deviation)\n","print(\"mean : \", mean) #\n","print(\"standard deviation: \", std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fZn4AxgFUI4","executionInfo":{"status":"ok","timestamp":1686751612459,"user_tz":-540,"elapsed":6,"user":{"displayName":"Eunki Joung","userId":"11847771242118286927"}},"outputId":"c18888a5-b3a3-4115-e0e4-221eb4e612a3"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["median :  507.0\n","MAD :  3.0\n","mean :  508.96049074074074\n","standard deviation:  7.95560041149137\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1jLgUqYZutE2ICoDrx20vRIXxpuaaX_4Y","timestamp":1686669981020},{"file_id":"1A6izbRy7JI8Zc7ocnmxUBCfGB7M6DGbI","timestamp":1686307508234}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}